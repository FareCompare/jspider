This document provides simple instructions for installing and running jspider.  For detailed instructions for running
and customizing jspider please refer to the User Manual jspider-0-5-0-doc-user.pdf in this same directory.

This is a copy of the jspider project found at http://j-spider.sourceforge.net/other/index.html and on Sourceforge at
http://sourceforge.net/projects/j-spider/.  Minor customizations have been made for our local use.

1. Build jspider
   mvn clean install

2. Deploy
   There are 3 configurations that use database output.  You will need to update the jspider.properties to set the
   database information.
      ~/jspider/conf/dboutput/jspider.properties - production environment
      ~/jspider/conf/dbalpha/jspider.properties - created for alpha environment
      ~/jspider/conf/dbstg/jspider.properties - created for stg environment

   The script deploy.sh is provided in the project home directory to copy the jspider runtime environment to a target
   server.

   Example ./deploy.sh myserver

   The above example will create the directory /usr/local/jspider on the target server named myserver and will copy
   the runtime and configuration directories into the /usr/local/jspider directory.

3. Initialize the database output tables.
   If you run the configuration named dboutput then you will first need to initialize the database tables.  The ddl
   script jspiderdb.sql will be copied into the bin directory by the deploy script.  On the target server cd to the
   bin directory and run the init_db.sh script.

   Example: ./init_db.sh myuserid

   The above will run mysql, logging on with the user "myuserid", and then run the jspiderdb.sql.  You will be prompted
   for the password.

4. Run jspider
   From the bin directory run the jspider script passing in the site you want to crawl and the configuration to use.

   Example:  ./jspider.sh http://www.mysite.com dboutput

   The above will cause jspider to crawl the www.mysite.com site and write output to the tables created in step 3.

5. Output
   Output is written to the seo_spider database. You can use the below query to list errors and what page they were
   referred by.

    -- counts by httpstatus
    SELECT httpstatus, COUNT(*) FROM jspider_resource GROUP BY 1 UNION SELECT 'TOTAL', COUNT(*) FROM jspider_resource;

    -- show non 200 urls
    SELECT 'id', 'url', 'httpstatus'
    UNION (
    SELECT r1.id, r1.url, r1.httpstatus
      INTO OUTFILE '/usr/local/jspider/output/non_200_resouces_D151215_01.csv'
           FIELDS TERMINATED BY ',' OPTIONALLY ENCLOSED BY '"'
           LINES TERMINATED BY '\n'
      FROM jspider_resource r1
     WHERE r1.httpstatus <> 0
       AND r1.httpstatus <> 200
     ORDER BY 1
    );

    -- show non 200 urls and their referer
    SELECT 'id', 'url', 'httpstatus', 'id', 'referer'
    UNION (
    SELECT r1.id, r1.url, r1.httpstatus, r2.id, r2.url as referer
      INTO OUTFILE '/usr/local/jspider/output/non_200_report_D150515_02.csv'
           FIELDS TERMINATED BY ',' OPTIONALLY ENCLOSED BY '"'
           LINES TERMINATED BY '\n'
      FROM jspider_resource r1, jspider_resource r2, jspider_resource_reference x
     WHERE r1.id = x.referee
       AND r2.id = referer
       AND r1.httpstatus <> 0
       AND r1.httpstatus <> 200
       -- AND r1.url like 'http://www.farecompare.com/flights/%'
       AND r1.url like 'http://alpha.farecompare.com/es/vuelos/%'
     ORDER BY 1
     );

    --
    -- Show not crawled
    -- These queries will show what urls in the url_validation table were not crawled. - Farecompare only
    --

    -- Temp table with urls that should be crawled
    DROP TABLE IF EXISTS temp_urls;
    CREATE TABLE temp_urls (
       url        VARCHAR(300) NOT NULL
    )
    ENGINE = InnoDB;
    INSERT INTO temp_urls SELECT CONCAT('http://www.farecompare.com',uri) FROM seo_ml.url_validation WHERE siteCode = 1 and returnCode = 200;
    INSERT INTO temp_urls SELECT CONCAT('http://www.farecompare.com/es',uri) FROM seo_ml.url_validation WHERE siteCode = 2 and returnCode = 200;
    ALTER TABLE temp_urls ADD INDEX (url);

    -- Temp table with urls that were crawled
    DROP TABLE IF EXISTS temp_urls_crawled;
    CREATE TABLE temp_urls_crawled (
       url        VARCHAR(300) NOT NULL
    )
    ENGINE = InnoDB;
    INSERT INTO temp_urls_crawled SELECT url FROM jspider_resource;
    ALTER TABLE temp_urls_crawled ADD INDEX (url);

    -- Not Crawled
    DROP TABLE IF EXISTS url_not_crawled_D151215_01;
    CREATE TABLE url_not_crawled_D151215_01 LIKE temp_urls;

    INSERT INTO url_not_crawled_D151215_01
    select u.url from temp_urls u
      left join temp_urls_crawled c on c.url = u.url
     where c.url is null;
